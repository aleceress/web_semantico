{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mulearn import FuzzyInductor\n",
    "from mulearn.kernel import PrecomputedKernel\n",
    "from mulearn.fuzzifier import *\n",
    "from mulearn.optimization import GurobiSolver\n",
    "import csv\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from mulearn.distributions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating and caching length_distance data matrix (could take considerable time)... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mdata_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/data-tettamanzi-complete.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mout_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mgram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'length_distance.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'length_distance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength_distance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36mget_data_matrix\u001b[1;34m(file, name, function, names)\u001b[0m\n\u001b[0;32m     44\u001b[0m               ' (could take considerable time)...'.format(name), end=' ')\n\u001b[0;32m     45\u001b[0m         data_matrix = np.array([[function(ax1, ax2)\n\u001b[1;32m---> 46\u001b[1;33m                                 for ax1 in names] for ax2 in names])\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m               ' (could take considerable time)...'.format(name), end=' ')\n\u001b[0;32m     45\u001b[0m         data_matrix = np.array([[function(ax1, ax2)\n\u001b[1;32m---> 46\u001b[1;33m                                 for ax1 in names] for ax2 in names])\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m               ' (could take considerable time)...'.format(name), end=' ')\n\u001b[0;32m     45\u001b[0m         data_matrix = np.array([[function(ax1, ax2)\n\u001b[1;32m---> 46\u001b[1;33m                                 for ax1 in names] for ax2 in names])\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf375bcfd5a5>\u001b[0m in \u001b[0;36mlength_distance\u001b[1;34m(ax1, ax2)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msign_negated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0max1_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0max1_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msign_negated\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Length-based Similarity experiments (generating matrix)\n",
    "def get_kernel_and_solver(gram):\n",
    "    eigvals = np.linalg.eigvals(gram)\n",
    "    assert(sum([abs(e.imag) for e in eigvals]) < 1e-4)\n",
    "    abs_neg_eigvals = [-l.real for l in eigvals if l < 0]\n",
    "    adjustment = max(abs_neg_eigvals) if abs_neg_eigvals else 0\n",
    "\n",
    "    kernel = PrecomputedKernel(gram)\n",
    "    solver = GurobiSolver(adjustment=adjustment) if adjustment else GurobiSolver()\n",
    "\n",
    "    return kernel, solver\n",
    "\n",
    "def _length_distance(ax1, ax2):\n",
    "    return abs(len(ax1) - len(ax2)) / max(len(ax1), len(ax2))\n",
    "\n",
    "\n",
    "\n",
    "def length_distance(ax1, ax2):\n",
    "    sign_negated = 1\n",
    "\n",
    "    ax1_clean = ax1[2:-1]\n",
    "    if ax1_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax1_clean = ax1_clean[1:]\n",
    "\n",
    "    ax2_clean = ax2[2:-1]\n",
    "    if ax2_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax2_clean = ax2_clean[1:]\n",
    "    \n",
    "    e = _length_distance(ax1_clean, ax2_clean)\n",
    "    \n",
    "    assert(0 <= e <= 1)\n",
    "    \n",
    "    return e if sign_negated == 1 else 1-e\n",
    "\n",
    "\n",
    "def get_data_matrix(file, name, function,names):\n",
    "    if os.path.isfile(file):\n",
    "        print('revrieving cached {} data matrix'.format(name))\n",
    "        data_matrix = np.load(file)\n",
    "    else:\n",
    "        print('generating and caching {} data matrix'\n",
    "              ' (could take considerable time)...'.format(name), end=' ')\n",
    "        data_matrix = np.array([[function(ax1, ax2)\n",
    "                                for ax1 in names] for ax2 in names])\n",
    "        np.save(file, data_matrix)\n",
    "        print('done!')\n",
    "    return data_matrix\n",
    "\n",
    "def get_dataset(filename):\n",
    "    with open(filename) as data_file:\n",
    "        data = np.array(list(csv.reader(data_file)))\n",
    "\n",
    "    n = len(data) - 1\n",
    "\n",
    "    # ## Extract data names, membership values and Gram matrix\n",
    "\n",
    "    names = np.array(data[0])[1:n+1]\n",
    "    mu = np.array([float(row[0]) for row in data[1:n+1]])\n",
    "    gram = get_data_matrix('length_distance.npy','length_distance',length_distance,names)\n",
    "\n",
    "    assert(len(names.shape) == 1)\n",
    "    assert(len(mu.shape) == 1)\n",
    "    assert(len(gram.shape) == 2)\n",
    "    assert(names.shape[0] == gram.shape[0] == gram.shape[1] == mu.shape[0])\n",
    "\n",
    "    X = np.array([[x] for x in np.arange(n)])\n",
    "\n",
    "    return X, gram, mu,names\n",
    "\n",
    "\n",
    "data_file_name = 'data/data-tettamanzi-complete.csv'\n",
    "X, gram, mu, names = get_dataset(data_file_name)\n",
    "\n",
    "out_cv = KFold()\n",
    "\n",
    "k, solver = get_kernel_and_solver(gram)\n",
    "\n",
    "fuzzifiers = [CrispFuzzifier(), QuantileConstantPiecewiseFuzzifier(), QuantileLinearPiecewiseFuzzifier(), LinearFuzzifier(), ExponentialFuzzifier(profile = 'alpha', alpha = 0.07)]\n",
    "mean_test_scores = []\n",
    "variance_test_scores = []\n",
    "mean_train_scores = []\n",
    "variance_train_scores = []\n",
    "\n",
    "for fuzzifier in fuzzifiers: \n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    i = 1\n",
    "    \n",
    "    fi = FuzzyInductor(k=k, solver=solver, fuzzifier= fuzzifier)\n",
    "\n",
    "    inner_folds = 5\n",
    "    rmse = make_scorer(mean_squared_error)\n",
    "    \n",
    "    gs = GridSearchCV(fi, {'c': np.logspace(-3, 3, 7)},\n",
    "                        verbose=0, cv=inner_folds,\n",
    "                        error_score= np.nan, scoring = rmse, n_jobs= 1,\n",
    "                        pre_dispatch=10, refit = True)\n",
    "\n",
    "    for train_idx, test_idx in out_cv.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        mu_train = mu[train_idx]\n",
    "        mu_test = mu[test_idx]\n",
    "\n",
    "        try:\n",
    "            gs.fit(X_train, mu_train)\n",
    "            print(f\"fold {i}: best parameters: {gs.best_params_['c']}\")\n",
    "            train_score = gs.score(X_train, mu_train)\n",
    "            test_score = gs.score(X_test, mu_test)\n",
    "            print(f'fold {i}: train score {train_score:.2f}, test score {test_score:.2f}')\n",
    "            test_scores.append(test_score)\n",
    "            train_scores.append(train_score)\n",
    "            i += 1\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            test_scores.append(np.nan)\n",
    "            train_scores.append(np.nan)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "    mean_test_scores.append(np.nanmean(test_scores))\n",
    "    mean_train_scores.append(np.nanmean(train_scores))\n",
    "    variance_test_scores.append(np.nanvar(test_scores))\n",
    "    variance_train_scores.append(np.nanvar(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>test variance</th>\n",
       "      <th>RMSE train</th>\n",
       "      <th>train variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CrispFuzzifier</th>\n",
       "      <td>0.323416</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.558929</td>\n",
       "      <td>0.010162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileConstantPiecewiseFuzzifier</th>\n",
       "      <td>0.217993</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.382215</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileLinearPiecewiseFuzzifier</th>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.366874</td>\n",
       "      <td>0.003613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExponentialFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE test  test variance  RMSE train  \\\n",
       "CrispFuzzifier                       0.323416       0.030826    0.558929   \n",
       "QuantileConstantPiecewiseFuzzifier   0.217993       0.000641    0.382215   \n",
       "QuantileLinearPiecewiseFuzzifier     0.223077       0.000873    0.366874   \n",
       "LinearFuzzifier                           NaN            NaN         NaN   \n",
       "ExponentialFuzzifier                      NaN            NaN         NaN   \n",
       "\n",
       "                                    train variance  \n",
       "CrispFuzzifier                            0.010162  \n",
       "QuantileConstantPiecewiseFuzzifier        0.003953  \n",
       "QuantileLinearPiecewiseFuzzifier          0.003613  \n",
       "LinearFuzzifier                                NaN  \n",
       "ExponentialFuzzifier                           NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'RMSE test' : mean_test_scores, 'test variance': variance_test_scores, 'RMSE train' : mean_train_scores, 'train variance' : variance_train_scores}\n",
    "df = pd.DataFrame(d, index = ['CrispFuzzifier', 'QuantileConstantPiecewiseFuzzifier', 'QuantileLinearPiecewiseFuzzifier','LinearFuzzifier', 'ExponentialFuzzifier'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating and caching hamming_distance data matrix (could take considerable time)... done!\n",
      "fold 1: best parameters: 0.1\n",
      "fold 1: train score 0.73, test score 0.85\n",
      "fold 2: best parameters: 1.0\n",
      "fold 2: train score 0.73, test score 0.58\n",
      "fold 3: best parameters: 0.01\n",
      "fold 3: train score 0.65, test score 0.19\n",
      "fold 4: best parameters: 1.0\n",
      "fold 4: train score 0.59, test score 0.57\n",
      "fold 5: best parameters: 0.01\n",
      "fold 5: train score 0.73, test score 0.23\n",
      "fold 1: best parameters: 1.0\n",
      "fold 1: train score 0.39, test score 0.47\n",
      "fold 2: best parameters: 1000.0\n",
      "fold 2: train score 0.46, test score 0.37\n",
      "fold 3: best parameters: 1000.0\n",
      "fold 3: train score 0.45, test score 0.33\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.45, test score 0.18\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.46, test score 0.36\n",
      "fold 1: best parameters: 1.0\n",
      "fold 1: train score 0.36, test score 0.46\n",
      "fold 2: best parameters: 1000.0\n",
      "fold 2: train score 0.43, test score 0.34\n",
      "fold 3: best parameters: 1000.0\n",
      "fold 3: train score 0.43, test score 0.38\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.43, test score 0.21\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.42, test score 0.36\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:123: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:124: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:125: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: Degrees of freedom <= 0 for slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:123: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:124: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:125: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: Degrees of freedom <= 0 for slice.\n"
     ]
    }
   ],
   "source": [
    "##Hamming distance based Similarity experiments(generating matrix)\n",
    "import os\n",
    "from nltk.metrics.distance import edit_distance as _edit_distance\n",
    "\n",
    "def get_kernel_and_solver(gram):\n",
    "    eigvals = np.linalg.eigvals(gram)\n",
    "    assert(sum([abs(e.imag) for e in eigvals]) < 1e-4)\n",
    "    abs_neg_eigvals = [-l.real for l in eigvals if l < 0]\n",
    "    adjustment = max(abs_neg_eigvals) if abs_neg_eigvals else 0\n",
    "\n",
    "    kernel = PrecomputedKernel(gram)\n",
    "    solver = GurobiSolver(adjustment=adjustment) if adjustment else GurobiSolver()\n",
    "\n",
    "    return kernel, solver\n",
    "\n",
    "def hamming(ax1, ax2):\n",
    "    sign_negated = 1\n",
    "\n",
    "    ax1_clean = ax1[2:-1]\n",
    "    if ax1_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax1_clean = ax1_clean[1:]\n",
    "\n",
    "    ax2_clean = ax2[2:-1]\n",
    "    if ax2_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax2_clean = ax2_clean[1:]\n",
    "\n",
    "    pairs = list(zip(ax1_clean, ax2_clean))\n",
    "    h = sum([ch1 != ch2\n",
    "             for ch1, ch2 in pairs]) / (min(len(ax1), len(ax2)) - 3)\n",
    "    # -3 here stands for \"do not consider quotes and initial space\"\n",
    "    \n",
    "    assert(0 <= h <= 1)\n",
    "    return h if sign_negated == 1 else 1-h\n",
    "\n",
    "\n",
    "def get_data_matrix(file, name, function,names):\n",
    "    if os.path.isfile(file):\n",
    "        print('revrieving cached {} data matrix'.format(name))\n",
    "        data_matrix = np.load(file)\n",
    "    else:\n",
    "        print('generating and caching {} data matrix'\n",
    "              ' (could take considerable time)...'.format(name), end=' ')\n",
    "        data_matrix = np.array([[function(ax1, ax2)\n",
    "                                for ax1 in names] for ax2 in names])\n",
    "        np.save(file, data_matrix)\n",
    "        print('done!')\n",
    "    return data_matrix\n",
    "\n",
    "def get_dataset(filename):\n",
    "    with open(filename) as data_file:\n",
    "        data = np.array(list(csv.reader(data_file)))\n",
    "\n",
    "    n = len(data) - 1\n",
    "\n",
    "    # ## Extract data names, membership values and Gram matrix\n",
    "\n",
    "    names = np.array(data[0])[1:n+1]\n",
    "    mu = np.array([float(row[0]) for row in data[1:n+1]])\n",
    "    gram = get_data_matrix('hamming_distance.npy','hamming_distance',hamming,names)\n",
    "\n",
    "    assert(len(names.shape) == 1)\n",
    "    assert(len(mu.shape) == 1)\n",
    "    assert(len(gram.shape) == 2)\n",
    "    assert(names.shape[0] == gram.shape[0] == gram.shape[1] == mu.shape[0])\n",
    "\n",
    "    X = np.array([[x] for x in np.arange(n)])\n",
    "\n",
    "    return X, gram, mu,names\n",
    "\n",
    "\n",
    "data_file_name = 'data/data-tettamanzi-complete.csv'\n",
    "X, gram, mu, names = get_dataset(data_file_name)\n",
    "\n",
    "out_cv = KFold()\n",
    "\n",
    "k, solver = get_kernel_and_solver(gram)\n",
    "\n",
    "fuzzifiers = [CrispFuzzifier(), QuantileConstantPiecewiseFuzzifier(), QuantileLinearPiecewiseFuzzifier(), LinearFuzzifier(), ExponentialFuzzifier(profile = 'alpha', alpha = 0.07)]\n",
    "mean_test_scores = []\n",
    "variance_test_scores = []\n",
    "mean_train_scores = []\n",
    "variance_train_scores = []\n",
    "\n",
    "for fuzzifier in fuzzifiers: \n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    i = 1\n",
    "    \n",
    "    fi = FuzzyInductor(k=k, solver=solver, fuzzifier= fuzzifier)\n",
    "\n",
    "    inner_folds = 5\n",
    "    rmse = make_scorer(mean_squared_error)\n",
    "    \n",
    "    gs = GridSearchCV(fi, {'c': np.logspace(-3, 3, 7)},\n",
    "                        verbose=0, cv=inner_folds,\n",
    "                        error_score= np.nan, scoring = rmse, n_jobs=-1,\n",
    "                        pre_dispatch=10, refit = True)\n",
    "\n",
    "    for train_idx, test_idx in out_cv.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        mu_train = mu[train_idx]\n",
    "        mu_test = mu[test_idx]\n",
    "\n",
    "        try:\n",
    "            gs.fit(X_train, mu_train)\n",
    "            print(f\"fold {i}: best parameters: {gs.best_params_['c']}\")\n",
    "            train_score = gs.score(X_train, mu_train)\n",
    "            test_score = gs.score(X_test, mu_test)\n",
    "            print(f'fold {i}: train score {train_score:.2f}, test score {test_score:.2f}')\n",
    "            test_scores.append(test_score)\n",
    "            train_scores.append(train_score)\n",
    "            i += 1\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            test_scores.append(np.nan)\n",
    "            train_scores.append(np.nan)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "    mean_test_scores.append(np.nanmean(test_scores))\n",
    "    mean_train_scores.append(np.nanmean(train_scores))\n",
    "    variance_test_scores.append(np.nanvar(test_scores))\n",
    "    variance_train_scores.append(np.nanvar(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>test variance</th>\n",
       "      <th>RMSE train</th>\n",
       "      <th>train variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CrispFuzzifier</th>\n",
       "      <td>0.484213</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.685165</td>\n",
       "      <td>0.003351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileConstantPiecewiseFuzzifier</th>\n",
       "      <td>0.341939</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.443161</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileLinearPiecewiseFuzzifier</th>\n",
       "      <td>0.348922</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.415319</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExponentialFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE test  test variance  RMSE train  \\\n",
       "CrispFuzzifier                       0.484213       0.059940    0.685165   \n",
       "QuantileConstantPiecewiseFuzzifier   0.341939       0.008224    0.443161   \n",
       "QuantileLinearPiecewiseFuzzifier     0.348922       0.006325    0.415319   \n",
       "LinearFuzzifier                           NaN            NaN         NaN   \n",
       "ExponentialFuzzifier                      NaN            NaN         NaN   \n",
       "\n",
       "                                    train variance  \n",
       "CrispFuzzifier                            0.003351  \n",
       "QuantileConstantPiecewiseFuzzifier        0.000801  \n",
       "QuantileLinearPiecewiseFuzzifier          0.000676  \n",
       "LinearFuzzifier                                NaN  \n",
       "ExponentialFuzzifier                           NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'RMSE test' : mean_test_scores, 'test variance': variance_test_scores, 'RMSE train' : mean_train_scores, 'train variance' : variance_train_scores}\n",
    "df = pd.DataFrame(d, index = ['CrispFuzzifier', 'QuantileConstantPiecewiseFuzzifier', 'QuantileLinearPiecewiseFuzzifier','LinearFuzzifier', 'ExponentialFuzzifier'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating and caching levenshtein_distance data matrix (could take considerable time)... done!\n",
      "fold 1: best parameters: 0.01\n",
      "fold 1: train score 0.74, test score 0.38\n",
      "fold 2: best parameters: 0.1\n",
      "fold 2: train score 0.74, test score 0.51\n",
      "fold 3: best parameters: 0.1\n",
      "fold 3: train score 0.67, test score 0.22\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.75, test score 0.54\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.70, test score 0.80\n",
      "fold 1: best parameters: 100.0\n",
      "fold 1: train score 0.40, test score 0.41\n",
      "fold 2: best parameters: 1000.0\n",
      "fold 2: train score 0.44, test score 0.41\n",
      "fold 3: best parameters: 1000.0\n",
      "fold 3: train score 0.45, test score 0.39\n",
      "fold 4: best parameters: 10.0\n",
      "fold 4: train score 0.41, test score 0.24\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.47, test score 0.39\n",
      "fold 1: best parameters: 100.0\n",
      "fold 1: train score 0.37, test score 0.43\n",
      "fold 2: best parameters: 1000.0\n",
      "fold 2: train score 0.42, test score 0.36\n",
      "fold 3: best parameters: 1000.0\n",
      "fold 3: train score 0.42, test score 0.40\n",
      "fold 4: best parameters: 1000.0\n",
      "fold 4: train score 0.38, test score 0.22\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.43, test score 0.37\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:124: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:125: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:127: RuntimeWarning: Degrees of freedom <= 0 for slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:124: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:125: RuntimeWarning: Mean of empty slice\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:127: RuntimeWarning: Degrees of freedom <= 0 for slice.\n"
     ]
    }
   ],
   "source": [
    "#Levenshtein distance based Similarity experiments(generating matrix)\n",
    "import os\n",
    "from nltk.metrics.distance import edit_distance as _edit_distance\n",
    "\n",
    "def get_kernel_and_solver(gram):\n",
    "    eigvals = np.linalg.eigvals(gram)\n",
    "    assert(sum([abs(e.imag) for e in eigvals]) < 1e-4)\n",
    "    abs_neg_eigvals = [-l.real for l in eigvals if l < 0]\n",
    "    adjustment = max(abs_neg_eigvals) if abs_neg_eigvals else 0\n",
    "\n",
    "    kernel = PrecomputedKernel(gram)\n",
    "    solver = GurobiSolver(adjustment=adjustment) if adjustment else GurobiSolver()\n",
    "\n",
    "    return kernel, solver\n",
    "\n",
    "def edit_distance(ax1, ax2):\n",
    "    sign_negated = 1\n",
    "\n",
    "    ax1_clean = ax1[2:-1]\n",
    "    if ax1_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax1_clean = ax1_clean[1:]\n",
    "\n",
    "    ax2_clean = ax2[2:-1]\n",
    "    if ax2_clean[0] == '-':\n",
    "        sign_negated *= -1\n",
    "        ax2_clean = ax2_clean[1:]\n",
    "    \n",
    "    e = _edit_distance(ax1_clean, ax2_clean) / (max(len(ax1), len(ax2)) - 3)\n",
    "    \n",
    "    # normalization here follows by the fact that the maximal edit\n",
    "    # distance between two words is the length of the longest word\n",
    "    # -3 here stands for \"do not consider quotes and initial space\"\n",
    "    assert(0 <= e <= 1)\n",
    "    \n",
    "    return e if sign_negated == 1 else 1-e\n",
    "\n",
    "\n",
    "def get_data_matrix(file, name, function,names):\n",
    "    if os.path.isfile(file):\n",
    "        print('revrieving cached {} data matrix'.format(name))\n",
    "        data_matrix = np.load(file)\n",
    "    else:\n",
    "        print('generating and caching {} data matrix'\n",
    "              ' (could take considerable time)...'.format(name), end=' ')\n",
    "        data_matrix = np.array([[function(ax1, ax2)\n",
    "                                for ax1 in names] for ax2 in names])\n",
    "        np.save(file, data_matrix)\n",
    "        print('done!')\n",
    "    return data_matrix\n",
    "\n",
    "def get_dataset(filename):\n",
    "    with open(filename) as data_file:\n",
    "        data = np.array(list(csv.reader(data_file)))\n",
    "\n",
    "    n = len(data) - 1\n",
    "\n",
    "    # ## Extract data names, membership values and Gram matrix\n",
    "\n",
    "    names = np.array(data[0])[1:n+1]\n",
    "    mu = np.array([float(row[0]) for row in data[1:n+1]])\n",
    "    gram = get_data_matrix('levenshtein_distance.npy','levenshtein_distance', edit_distance, names)\n",
    "\n",
    "    assert(len(names.shape) == 1)\n",
    "    assert(len(mu.shape) == 1)\n",
    "    assert(len(gram.shape) == 2)\n",
    "    assert(names.shape[0] == gram.shape[0] == gram.shape[1] == mu.shape[0])\n",
    "\n",
    "    X = np.array([[x] for x in np.arange(n)])\n",
    "\n",
    "    return X, gram, mu,names\n",
    "\n",
    "\n",
    "data_file_name = 'data/data-tettamanzi-complete.csv'\n",
    "X, gram, mu, names = get_dataset(data_file_name)\n",
    "\n",
    "out_cv = KFold()\n",
    "\n",
    "k, solver = get_kernel_and_solver(gram)\n",
    "\n",
    "fuzzifiers = [CrispFuzzifier(), QuantileConstantPiecewiseFuzzifier(), QuantileLinearPiecewiseFuzzifier(), LinearFuzzifier(), ExponentialFuzzifier(profile = 'alpha', alpha = 0.07)]\n",
    "mean_test_scores = []\n",
    "variance_test_scores = []\n",
    "mean_train_scores = []\n",
    "variance_train_scores = []\n",
    "\n",
    "for fuzzifier in fuzzifiers: \n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    i = 1\n",
    "    \n",
    "    fi = FuzzyInductor(k=k, solver=solver, fuzzifier= fuzzifier)\n",
    "\n",
    "    inner_folds = 5\n",
    "    rmse = make_scorer(mean_squared_error)\n",
    "    \n",
    "    gs = GridSearchCV(fi, {'c': np.logspace(-3, 3, 7)},\n",
    "                        verbose=0, cv=inner_folds,\n",
    "                        error_score= np.nan, scoring = rmse, n_jobs=-1,\n",
    "                        pre_dispatch=10, refit = True)\n",
    "\n",
    "    for train_idx, test_idx in out_cv.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        mu_train = mu[train_idx]\n",
    "        mu_test = mu[test_idx]\n",
    "\n",
    "        try:\n",
    "            gs.fit(X_train, mu_train)\n",
    "            print(f\"fold {i}: best parameters: {gs.best_params_['c']}\")\n",
    "            train_score = gs.score(X_train, mu_train)\n",
    "            test_score = gs.score(X_test, mu_test)\n",
    "            print(f'fold {i}: train score {train_score:.2f}, test score {test_score:.2f}')\n",
    "            test_scores.append(test_score)\n",
    "            train_scores.append(train_score)\n",
    "            i += 1\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            test_scores.append(np.nan)\n",
    "            train_scores.append(np.nan)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "    mean_test_scores.append(np.nanmean(test_scores))\n",
    "    mean_train_scores.append(np.nanmean(train_scores))\n",
    "    variance_test_scores.append(np.nanvar(test_scores))\n",
    "    variance_train_scores.append(np.nanvar(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>test variance</th>\n",
       "      <th>RMSE train</th>\n",
       "      <th>train variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CrispFuzzifier</th>\n",
       "      <td>0.488398</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>0.722092</td>\n",
       "      <td>0.000910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileConstantPiecewiseFuzzifier</th>\n",
       "      <td>0.368341</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.431938</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileLinearPiecewiseFuzzifier</th>\n",
       "      <td>0.355627</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.404547</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExponentialFuzzifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE test  test variance  RMSE train  \\\n",
       "CrispFuzzifier                       0.488398       0.036885    0.722092   \n",
       "QuantileConstantPiecewiseFuzzifier   0.368341       0.003982    0.431938   \n",
       "QuantileLinearPiecewiseFuzzifier     0.355627       0.004829    0.404547   \n",
       "LinearFuzzifier                           NaN            NaN         NaN   \n",
       "ExponentialFuzzifier                      NaN            NaN         NaN   \n",
       "\n",
       "                                    train variance  \n",
       "CrispFuzzifier                            0.000910  \n",
       "QuantileConstantPiecewiseFuzzifier        0.000667  \n",
       "QuantileLinearPiecewiseFuzzifier          0.000526  \n",
       "LinearFuzzifier                                NaN  \n",
       "ExponentialFuzzifier                           NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'RMSE test' : mean_test_scores, 'test variance': variance_test_scores, 'RMSE train' : mean_train_scores, 'train variance' : variance_train_scores}\n",
    "df = pd.DataFrame(d, index = ['CrispFuzzifier', 'QuantileConstantPiecewiseFuzzifier', 'QuantileLinearPiecewiseFuzzifier','LinearFuzzifier', 'ExponentialFuzzifier'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
