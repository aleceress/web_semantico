{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1: best parameters: 0.1\n",
      "fold 1: train score 0.00, test score 0.00\n",
      "fold 2: best parameters: 0.1\n",
      "fold 2: train score 0.00, test score 0.04\n",
      "fold 3: best parameters: 0.1\n",
      "fold 3: train score 0.00, test score 0.00\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.00, test score 0.00\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.00, test score 0.00\n",
      "fold 1: best parameters: 0.1\n",
      "fold 1: train score 0.06, test score 0.13\n",
      "fold 2: best parameters: 0.1\n",
      "fold 2: train score 0.06, test score 0.12\n",
      "fold 3: best parameters: 0.1\n",
      "fold 3: train score 0.06, test score 0.13\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.06, test score 0.14\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.06, test score 0.11\n",
      "fold 1: best parameters: 0.1\n",
      "fold 1: train score 0.05, test score 0.13\n",
      "fold 2: best parameters: 0.1\n",
      "fold 2: train score 0.05, test score 0.13\n",
      "fold 3: best parameters: 0.1\n",
      "fold 3: train score 0.05, test score 0.13\n",
      "fold 4: best parameters: 0.1\n",
      "fold 4: train score 0.05, test score 0.13\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.05, test score 0.12\n",
      "-0.005805772743129323\n",
      "-0.015268623321032071\n",
      "-0.012138625748200571\n",
      "-0.009384121419380609\n",
      "-0.008441304208052336\n",
      "-0.30143129443486405\n",
      "-0.4174026823455135\n",
      "-0.3883818036816613\n",
      "-0.3018532118291669\n",
      "-0.2452893738161792\n",
      "-0.43321230354101165\n",
      "-0.5225028119586541\n",
      "-0.47374804877304266\n",
      "-0.42102968675954244\n",
      "-0.3350401904085395\n",
      "-0.5467545570427108\n",
      "-0.5356001553590914\n",
      "-0.6039855788000802\n",
      "-0.542864170436612\n",
      "-0.4409392490152647\n",
      "-0.6246189249688355\n",
      "-0.5829531652392561\n",
      "-0.7226782058003364\n",
      "-0.6533776460609904\n",
      "-0.5451202194474998\n",
      "-0.016237362567353975\n",
      "fold 1: best parameters: 0.1\n",
      "fold 1: train score 0.00, test score 0.00\n",
      "-0.008357243796468072\n",
      "-0.01568294089987754\n",
      "-0.015644583127144007\n",
      "-0.012688599640982567\n",
      "-0.010602774579721252\n",
      "-0.3789246247449508\n",
      "-0.4246008269799948\n",
      "-0.4851124144462706\n",
      "-0.3881245045143916\n",
      "-0.3189855841761362\n",
      "-0.5199696651961012\n",
      "-0.566473600911735\n",
      "-0.6109035066181859\n",
      "-0.5498396030724004\n",
      "-0.44699012875077015\n",
      "-0.5953154352195081\n",
      "-0.6063001895203136\n",
      "-0.7317385410507172\n",
      "-0.6647704710460892\n",
      "-0.5518554685924487\n",
      "-0.6762260883860371\n",
      "-0.6203672093149911\n",
      "-0.7997006426887593\n",
      "-0.7425646164131807\n",
      "-0.6292693007094295\n",
      "-0.019881738846162733\n",
      "fold 2: best parameters: 0.1\n",
      "fold 2: train score 0.00, test score 0.02\n",
      "-0.014050707096884163\n",
      "-0.01288181250487952\n",
      "-0.025893099731867375\n",
      "-0.018826287062607028\n",
      "-0.01670691333880192\n",
      "-0.4088562942580828\n",
      "-0.37503699593718254\n",
      "-0.5643621447089353\n",
      "-0.41650019299810037\n",
      "-0.34588163978899444\n",
      "-0.4949293617452203\n",
      "-0.49462652021367803\n",
      "-0.6524327102244218\n",
      "-0.5243142398197885\n",
      "-0.4259624997818885\n",
      "-0.5504229214991834\n",
      "-0.5896246591776865\n",
      "-0.694621819400822\n",
      "-0.6173687052965621\n",
      "-0.5120859901611963\n",
      "-0.5976736517241829\n",
      "-0.6411351146481746\n",
      "-0.7042636592188246\n",
      "-0.6632609109825405\n",
      "-0.5584744576209125\n",
      "-0.026653385151968134\n",
      "fold 3: best parameters: 0.1\n",
      "fold 3: train score 0.00, test score 0.00\n",
      "-0.011069943203819377\n",
      "-0.010407056088607147\n",
      "-0.022000031849604085\n",
      "-0.01900149558900932\n",
      "-0.013601570766391347\n",
      "-0.3798058851272077\n",
      "-0.34665451668018876\n",
      "-0.4840940020049892\n",
      "-0.4634402400224242\n",
      "-0.3192209843641862\n",
      "-0.47662739978947777\n",
      "-0.47701242604054744\n",
      "-0.6123127501064365\n",
      "-0.545319236982886\n",
      "-0.4088087580341322\n",
      "-0.6050421316249683\n",
      "-0.6472058439110554\n",
      "-0.6902578734194754\n",
      "-0.6747610241150882\n",
      "-0.5612233795759903\n",
      "-0.7207952658315434\n",
      "-0.7658879798626083\n",
      "-0.6965094463671957\n",
      "-0.7839049434990796\n",
      "-0.6701585411506397\n",
      "-0.8159233032060418\n",
      "fold 4: best parameters: 100.0\n",
      "fold 4: train score 0.00, test score 0.00\n",
      "-0.00912370560349507\n",
      "-0.007700471885646376\n",
      "-0.018974320219413476\n",
      "-0.01791357638433433\n",
      "-0.012025178008670534\n",
      "-0.2793437052970751\n",
      "-0.2532849697503434\n",
      "-0.3725265297076127\n",
      "-0.3884453179268377\n",
      "-0.2835117086650173\n",
      "-0.37306396546943366\n",
      "-0.37625709853961087\n",
      "-0.49734093833702875\n",
      "-0.4752729441067478\n",
      "-0.36966419385218263\n",
      "-0.4876673181188189\n",
      "-0.5246972430022747\n",
      "-0.5703353416605242\n",
      "-0.5966156719301244\n",
      "-0.5172256699708511\n",
      "-0.5965365693120884\n",
      "-0.639033002357257\n",
      "-0.5832592959349281\n",
      "-0.7080237260336801\n",
      "-0.6253830558687458\n",
      "-0.020097081030143515\n",
      "fold 5: best parameters: 0.1\n",
      "fold 5: train score 0.00, test score 0.00\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n",
      "optimal solution not found!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 26 12:06:53 2020.\n",
    "\n",
    "@author: malchiodi\n",
    "\"\"\"\n",
    "\n",
    "from mulearn import FuzzyInductor\n",
    "from mulearn.kernel import PrecomputedKernel\n",
    "from mulearn.fuzzifier import *\n",
    "from mulearn.optimization import GurobiSolver\n",
    "import csv\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from mulearn.distributions import *\n",
    "\n",
    "def get_kernel_and_solver(gram):\n",
    "    eigvals = np.linalg.eigvals(gram)\n",
    "    assert(sum([abs(e.imag) for e in eigvals]) < 1e-4)\n",
    "    abs_neg_eigvals = [-l.real for l in eigvals if l < 0]\n",
    "    adjustment = max(abs_neg_eigvals) if abs_neg_eigvals else 0\n",
    "\n",
    "    kernel = PrecomputedKernel(gram)\n",
    "    solver = GurobiSolver(adjustment=adjustment) if adjustment else GurobiSolver()\n",
    "\n",
    "    return kernel, solver\n",
    "\n",
    "def get_dataset(filename):\n",
    "    with open(filename) as data_file:\n",
    "        data = np.array(list(csv.reader(data_file)))\n",
    "\n",
    "    n = len(data) - 1\n",
    "    n = 100\n",
    "\n",
    "    # ## Extract data names, membership values and Gram matrix\n",
    "\n",
    "    names = np.array(data[0])[1:n+1]\n",
    "    mu = np.array([float(row[0]) for row in data[1:n+1]])\n",
    "    gram = np.array([[float(k.replace('NA', '0')) for k in row[1:n+1]]\n",
    "                     for row in data[1:n+1]])\n",
    "\n",
    "    assert(len(names.shape) == 1)\n",
    "    assert(len(mu.shape) == 1)\n",
    "    assert(len(gram.shape) == 2)\n",
    "\n",
    "    assert(names.shape[0] == gram.shape[0] == gram.shape[1] == mu.shape[0])\n",
    "\n",
    "    X = np.array([[x] for x in np.arange(n)])\n",
    "\n",
    "    return X, gram, mu\n",
    "\n",
    "\n",
    "data_file_name = 'data/data-tettamanzi-complete.csv'\n",
    "X, gram, mu = get_dataset(data_file_name)\n",
    "\n",
    "\n",
    "out_cv = KFold()\n",
    "\n",
    "k, solver = get_kernel_and_solver(gram)\n",
    "\n",
    "fuzzifiers = [CrispFuzzifier(), QuantileConstantPiecewiseFuzzifier(), QuantileLinearPiecewiseFuzzifier(), LinearFuzzifier(), ExponentialFuzzifier(profile = 'alpha', alpha = 0.07)]\n",
    "mean_scores = []\n",
    "variance_scores = []\n",
    "\n",
    "for fuzzifier in fuzzifiers: \n",
    "    test_scores = []\n",
    "    i = 1\n",
    "    \n",
    "    fi = FuzzyInductor(k=k, solver=solver, fuzzifier= fuzzifier)\n",
    "\n",
    "    inner_folds = 5\n",
    "    rmse = make_scorer(mean_squared_error)\n",
    "    \n",
    "    gs = GridSearchCV(fi, {'c': np.logspace(-3, 3, 7)},\n",
    "                        verbose=0, cv=inner_folds,\n",
    "                        error_score= np.nan, scoring = rmse, n_jobs= 1,\n",
    "                        pre_dispatch=10, refit = True)\n",
    "\n",
    "    for train_idx, test_idx in out_cv.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        mu_train = mu[train_idx]\n",
    "        mu_test = mu[test_idx]\n",
    "\n",
    "        try:\n",
    "            gs.fit(X_train, mu_train)\n",
    "            print(f\"fold {i}: best parameters: {gs.best_params_['c']}\")\n",
    "            #e = rs.estimator.set_params(**rs.best_params_)\n",
    "            train_score = gs.score(X_train, mu_train)\n",
    "            test_score = gs.score(X_test, mu_test)\n",
    "            print(f'fold {i}: train score {train_score:.2f}, test score {test_score:.2f}')\n",
    "            test_scores.append(test_score)\n",
    "            i += 1\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            test_scores.append(np.nan)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "    mean_scores.append(statistics.mean(test_scores))\n",
    "    variance_scores.append(statistics.variance(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'mean rmse' : mean_scores, 'variance': variance_scores}\n",
    "df = pd.DataFrame(d, index = ['CrispFuzzifier', 'QuantileConstantPiecewiseFuzzifier', 'QuantileLinearPiecewiseFuzzifier','LinearFuzzifier', 'ExponentialFuzzifier'])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
